{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "# Flow ML Course\n",
    "\n",
    "# TP 5 : HyperParameter Tuning avec Vertex AI TensorBoard\n",
    "\n",
    "L'objectif de ce TP est de réaliser un hyper-paramétrage de modèe utilisant Vertex AI TensorBoard pour logger les hyper-paramètres et leurs métriques de performances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Ce tutoriel utilise le dataset [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0316df526f8"
   },
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "th7tWguZiSN2"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform[tensorboard] \\\n",
    "                                 tensorflow==2.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"projet-ia-448520\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "your_name = ...\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bea5ee30d9ca"
   },
   "source": [
    "## Vertex AI TensorBoard?\n",
    "\n",
    "Vertex AI TensorBoard est un version de Tensorboard : [Open source TensorBoard](https://www.tensorflow.org/tensorboard/get_started)\n",
    "(TB). \n",
    "C'est un projet Google open source pour la visualisation d'experiment de machine learning : \n",
    "\n",
    "\n",
    "\n",
    "*   suivi et visualisation des métriques\n",
    "*   architecture du modèles (computational graphs i.e ops and layers),\n",
    "*   projection d'embeddings\n",
    "*   image, text, audio ...\n",
    "\n",
    "Vertex AI TensorBoard fournit en plus des fonctionnalités de TensorBoard : \n",
    "\n",
    "*  un lien partageable et persistent au dashboard,\n",
    "*  liste des experiments du projet\n",
    "*  intégrtion avec les service Vertex AI\n",
    "*  enterprise-grade security, privacy, and compliance.\n",
    "\n",
    "Approfondir ici : [Vertex AI TensorBoard](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjWD61gONRkw"
   },
   "source": [
    "## Composants TensorBoard et TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSayPNqxfJC_"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/\n",
    "\n",
    "# Import TensorFlow and the TensorBoard HParams plugin\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJ4zE7rYfcvb"
   },
   "source": [
    "## Download dataset\n",
    "\n",
    "Télécharge le dataset et noramliser le [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHME9wnnfiMr"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn \n",
    "\n",
    "Normalize X train / test between [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofGSMru5r4kP"
   },
   "source": [
    "## Set up experiment\n",
    "\n",
    "Réaliser une première experiement en spécifiants les hyper-paramètres suivants :s:\n",
    "\n",
    "* number of units in the first dense layer\n",
    "* dropout rate\n",
    "* optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "Définisser le range des valeurs d'hyper-paramètres\n",
    "- Utiliser hp.Discrete or hp.RealInterval\n",
    "- Choisissez votre métriques\n",
    "\n",
    "Expliquer vos choix : \n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IG5sPLBAcDRy"
   },
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam(\"num_units\", ...)\n",
    "HP_DROPOUT = hp.HParam(\"dropout\", ...)\n",
    "HP_OPTIMIZER = hp.HParam(\"optimizer\", ...)\n",
    "\n",
    "METRIC_NAME = ...\n",
    "\n",
    "with tf.summary.create_file_writer(\"logs/hparam_tuning\").as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_NAME, display_name=METRIC_NAME)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLNgBNA6srlk"
   },
   "source": [
    "## Adapter les runs Tensorflow \n",
    "\n",
    "Définissez l'architecture de votre modèle avec keras. Faites en sorte que les hyper-paramètres soient utilisés dans la fonction d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-RSsrF4u-Fq"
   },
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model = ... # Define your achitecure\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss=..., # Choose your loss\n",
    "        metrics=[METRIC_NAME],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train, epochs=1\n",
    "    )  # Run with 1 epoch to speed things up for demo purposes\n",
    "    _, accuracy = model.evaluate(..., ...) # to complete\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Esz3uqqCvLoK"
   },
   "source": [
    "Pour chaque run, logger les hyper-paramètres et la métrique choisie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwR1PAv1vPER"
   },
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_NAME, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V_8soFFvU7b"
   },
   "source": [
    "## Start runs and log them all under one parent directory\n",
    "\n",
    "Lancer l'hyper-paramétrage en réalisant plusieurs run avec un set d'hyper-paramètres différents.\n",
    "\n",
    "Utiliser un grid search avec peu de combinaisons pour accélérer le processus. Pour les range de valeurs continues utiliser seulement le min et le max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6r2oO_PVvbdL"
   },
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print(\"--- Starting trial: %s\" % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run(\"logs/hparam_tuning/\" + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkbB5GEI3Ge3"
   },
   "source": [
    "## Create Vertex AI TensorBoard\n",
    "Créer une instance Tensorboard pour visualiser votre entrainement.\n",
    "\n",
    "Plus de détail ici : [Create a Vertex AI TensorBoard instance](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-setup#create-tensorboard-instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQ-d3j-I3ZWV"
   },
   "outputs": [],
   "source": [
    "# Set the display name for your tensorboard instance\n",
    "\n",
    "TENSORBOARD_NAME = f\"supaero-vertex-course-1-tb-{PROJECT_ID}-{your_name}\"  # @param {type:\"string\"}\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_NAME, project=PROJECT_ID, location=LOCATION\n",
    ")\n",
    "TENSORBOARD_RESOURCE_NAME = tensorboard.gca_resource.name\n",
    "print(\"TensorBoard resource name:\", TENSORBOARD_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OU4TMtFCn0_"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = f\"supaero-vertex-course-1-5-{PROJECT_ID}-{your_name}\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1D2oU3K8Ys0"
   },
   "source": [
    "Upload the log to your Vertex AI TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyXFVQuRv0-X"
   },
   "outputs": [],
   "source": [
    "!tb-gcp-uploader --one_shot=True --tensorboard_resource_name=$TENSORBOARD_RESOURCE_NAME --logdir=\"logs/hparam_tuning/\" --experiment_name=$EXPERIMENT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFe3qRyh9Wjl"
   },
   "source": [
    "## Visualiser vos Résultats\n",
    "\n",
    "Cliquer sur le lien générer par la cellule ci-dessus ou aller dans le portail Vertex AI. Les fonctionnalités disponibles sont :\n",
    "\n",
    "- Filtre et tri sur les hyper-paramètres, les métriques, et le status des runs\n",
    "- Sélection des runs\n",
    "\n",
    "Le dashboard HParams dashboard possède 3 vues différentes :\n",
    "\n",
    "* Listing des runs, hyper-paramètres et métriques :  **Table View** \n",
    "* Comparaison de runs interactives via les hyper-paramètres :  **Parallel Coordinates View** \n",
    "* Comparaison de runs interactives via les métriques : **Scatter Plot Matrix View** shows plots \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Quels hyper-paramètres permettent d'obtenir les meilleurs performances ? (check via le tensorboard)\n",
    "\n",
    "Est-ce logique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer : "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tensorboard_hyperparameter_tuning_with_hparams.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-17.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
